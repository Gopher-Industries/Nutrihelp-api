#!/usr/bin/env python3
"""
NutriHelp Security Scanner V2.0 - Core Engine
"""

import os
import sys
import importlib
import logging
import re
from typing import List, Dict, Any, Optional
from pathlib import Path
import uuid
from datetime import datetime

# Add the plugin directory to the Python path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from plugins.base_plugin import BaseSecurityPlugin, PluginManager, SecurityFinding


class VulnerabilityScannerEngine:
    """Vulnerability Scanner Engine Core Class"""

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or {}
        self.plugin_manager = PluginManager()
        self.logger = logging.getLogger("VulnerabilityScannerEngine")
        self._setup_logging()

        # Statistics
        self.stats = {
            'files_scanned': 0,
            'total_findings': 0,
            'plugins_loaded': 0
        }
    
    def _setup_logging(self):
        """Set up logging configuration"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(),
                # can add file processors
            ]
        )
    
    def load_plugins(self, plugin_configs: Optional[Dict[str, Any]] = None):
        """Dynamically load plugins"""
        plugin_configs = plugin_configs or {}
        plugins_loaded = 0

        # Define plugin mappings
        plugin_mappings = {
            'jwt_missing_protection': 'plugins.jwt_security.jwt_missing',
            'jwt_configuration': 'plugins.jwt_security.jwt_config',
            # General security plugin
            'general_security': 'plugins.general_security',
            # RLS plugin removed to fix dependency issues
        }
        
        for plugin_name, module_path in plugin_mappings.items():
            plugin_config_raw = plugin_configs.get(plugin_name, {})

            # Support two shapes: either {plugin: {'config': {...}, 'enabled': True}} or {plugin: {...}}
            # If caller provided a wrapper with 'config', prefer that; otherwise treat the value as the config itself.
            plugin_config = plugin_config_raw.get('config', plugin_config_raw) if isinstance(plugin_config_raw, dict) else {}

            # Check if the plugin is enabled (allow enabled flag at the top-level of provided mapping)
            enabled_flag = plugin_config_raw.get('enabled', True) if isinstance(plugin_config_raw, dict) else True
            if not enabled_flag:
                self.logger.info(f"Plugin {plugin_name} is disabled")
                continue
            
            try:
                # Dynamically import plugin module
                module = importlib.import_module(module_path)

                # Find plugin class (convention: ends with Plugin)
                plugin_class = None
                for attr_name in dir(module):
                    attr = getattr(module, attr_name)
                    if (isinstance(attr, type) and 
                        issubclass(attr, BaseSecurityPlugin) and 
                        attr != BaseSecurityPlugin):
                        plugin_class = attr
                        break
                
                if plugin_class:
                    plugin_instance = plugin_class(plugin_config)
                    self.plugin_manager.register_plugin(plugin_instance)
                    plugins_loaded += 1
                else:
                    self.logger.warning(f"No plugin class found in {module_path}")
                    
            except ImportError as e:
                self.logger.warning(f"Could not load plugin {plugin_name}: {e}")
            except Exception as e:
                self.logger.error(f"Error loading plugin {plugin_name}: {e}")
        
        self.stats['plugins_loaded'] = plugins_loaded
        self.logger.info(f"Loaded {plugins_loaded} plugins")
    
    def _count_by_severity(self, findings: List[Any]) -> Dict[str, int]:
        """Count findings by severity level."""
        severity_counts = {}
        for finding in findings:
            # Handle both object and dict findings
            if hasattr(finding, 'severity'):
                severity = finding.severity
            else:
                severity = finding.get('severity', 'UNKNOWN')
            
            severity = str(severity).upper()
            severity_counts[severity] = severity_counts.get(severity, 0) + 1
        return severity_counts

    def _count_by_plugin(self, findings: List[Any]) -> Dict[str, int]:
        """Count findings by plugin name."""
        plugin_counts = {}
        for finding in findings:
            # Handle both object and dict findings
            if hasattr(finding, 'plugin'):
                plugin = finding.plugin
            elif isinstance(finding, dict):
                # plugins may serialize under 'plugin_name'
                plugin = finding.get('plugin_name') or finding.get('plugin') or 'Unknown'
            else:
                plugin = 'Unknown'
            
            plugin_counts[plugin] = plugin_counts.get(plugin, 0) + 1
        return plugin_counts

    def scan_target(self, target_path: str) -> Dict:
        """
        Run all security plugins on the target.
        """
        self.logger.info(f"Starting security scan on: {target_path}")

        # Discover global app.use protections (best-effort)
        self.global_protected_prefixes = self._discover_global_app_use_protections(target_path)
        self.logger.debug(f"Discovered protected prefixes: {self.global_protected_prefixes}")

        all_findings = []

        # Make sure to count the number of files first
        files_scanned = self._count_scannable_files(target_path)
        self.stats['files_scanned'] = files_scanned

        for plugin in self.plugin_manager.plugins:
            try:
                # Merge engine-level global excludes into plugin config so plugin-level
                # checks (is_file_scannable / should_skip_directory / read_file_safe) honor them.
                engine_excludes = self.config.get('global_exclude_paths', []) or []
                plugin_excludes = plugin.config.get('exclude_paths', []) or []
                # preserve order but avoid duplicates
                merged = []
                for p in engine_excludes + plugin_excludes:
                    if p and p not in merged:
                        merged.append(p)
                plugin.config['exclude_paths'] = merged

                findings = plugin.scan(target_path)
                if findings:
                    # Process each finding
                    for finding in findings:
                        # Prefer plugin-provided recommendation; generate only if missing/empty
                        existing_rec = None
                        if hasattr(finding, 'recommendation'):
                            existing_rec = getattr(finding, 'recommendation')
                        elif isinstance(finding, dict):
                            existing_rec = finding.get('recommendation')

                        if not existing_rec:
                            # Generate and add recommendation only when plugin didn't provide one
                            recommendation = self._generate_recommendation(
                                finding.title if hasattr(finding, 'title') else finding.get('title', ''),
                                finding.file_path if hasattr(finding, 'file_path') else finding.get('file_path', '')
                            )

                            # If finding is an object
                            if hasattr(finding, 'recommendation'):
                                finding.recommendation = recommendation
                            # If finding is a dictionary
                            elif isinstance(finding, dict):
                                finding['recommendation'] = recommendation

                        # Ensure other attributes exist
                        if hasattr(finding, 'plugin') and not getattr(finding, 'plugin', None):
                            finding.plugin = plugin.__class__.__name__
                        if hasattr(finding, 'file_path') and not getattr(finding, 'file_path', None):
                            finding.file_path = target_path

                    all_findings.extend(findings)
            except Exception as e:
                self.logger.error(f"Plugin {plugin.__class__.__name__} failed: {e}")

        # Convert findings to ensure recommendations are included
        findings_dict = []
        for f in all_findings:
            if hasattr(f, 'to_dict'):
                finding_dict = f.to_dict()
                # Ensure recommendation is included in the dictionary
                if hasattr(f, 'recommendation'):
                    finding_dict['recommendation'] = f.recommendation
                findings_dict.append(finding_dict)
            else:
                findings_dict.append(f)

        # Sanitize findings: remove malformed entries and findings matching excluded paths
        findings_dict = self._sanitize_findings(findings_dict, target_path)
        # Use sanitized findings for summary/stats to reflect what is reported
        total_clean = len(findings_dict)
        by_sev = self._count_by_severity(findings_dict)
        by_plug = self._count_by_plugin(findings_dict)

        # update engine stats
        try:
            self.stats['total_findings'] = total_clean
        except Exception:
            self.stats['total_findings'] = total_clean

        # consistent timestamp for both top-level and scan_info
        ts = datetime.now().isoformat()

        return {
            'scan_id': str(uuid.uuid4()),
            'target': target_path,
            'timestamp': ts,
            'findings': findings_dict,  # Use the processed findings
            'summary': {
                'total': total_clean,
                'files_scanned': files_scanned,
                'by_severity': by_sev,
                'by_plugin': by_plug
            },
            'scan_info': {
                'target_path': target_path,
                'timestamp': ts,
                'scanner_version': "2.0.0",
                'stats': {
                    'files_scanned': files_scanned,
                    'plugins_loaded': len(self.plugin_manager.plugins),
                    'total_findings': total_clean
                }
            }
        }

    # Backwards compatibility: keep old name as an alias for imports in other modules/tests
    # (moved to module-level after class definition)
    
    def _count_scannable_files(self, target_path: str) -> int:
        """Count scannable files"""
        count = 0
        for root, dirs, files in os.walk(target_path):
            # Skip directories that should not be scanned
            dirs[:] = [d for d in dirs if not self._should_skip_dir(os.path.join(root, d))]
            
            for file in files:
                file_path = os.path.join(root, file)
                # Respect engine-level global_exclude_paths during counting
                if self._is_excluded_path(file_path):
                    continue
                if self._is_scannable_file(file_path):
                    count += 1
        return count

    def _discover_global_app_use_protections(self, target_path: str) -> List[str]:
        """Best-effort discovery of app.use mounts that include trusted middleware.

        Looks for patterns like: app.use('/api', authenticateToken, router)
        or app.use('/api', authenticateToken, otherRouter)
        Returns list of path prefixes (e.g. ['/api', '/admin']).
        """
        prefixes = []
        scanner_cfg = self.config.get('scanner', {}) or {}
        trusted = scanner_cfg.get('trusted_global_middlewares', []) or []

        # simple regex to capture app.use('<prefix>', <middleware>, <router>)
        pattern = re.compile(r"app\.use\s*\(\s*['\"](?P<prefix>/[^'\"]*)['\"]\s*,\s*(?P<mw>[^,\)]+)", re.IGNORECASE)

        for root, dirs, files in os.walk(target_path):
            # do not descend into virtual envs or excluded dirs
            dirs[:] = [d for d in dirs if not self._should_skip_dir(os.path.join(root, d))]
            for fname in files:
                if not fname.endswith('.js') and not fname.endswith('.ts'):
                    continue
                fpath = os.path.join(root, fname)
                try:
                    with open(fpath, 'r', encoding='utf-8', errors='ignore') as fh:
                        content = fh.read()
                except Exception:
                    continue

                for m in pattern.finditer(content):
                    prefix = m.group('prefix')
                    mw_expr = m.group('mw').strip()
                    # mw_expr may be like 'authenticateToken' or 'authenticateToken,' or 'authenticateToken, router'
                    # normalize name
                    mw_name = re.split(r'[,\s\(\)]', mw_expr)[0]
                    if mw_name in trusted:
                        if prefix not in prefixes:
                            prefixes.append(prefix)

        return prefixes

    def _is_excluded_path(self, file_path: str) -> bool:
        """Return True if the given path should be excluded by engine-level global rules."""
        try:
            excludes = self._get_global_excludes()
            # substring-based excludes (backwards compatible)
            for p in excludes:
                if p and p in file_path:
                    return True

            # path-segment based excludes: prevent matching arbitrary 'test_' substrings
            test_dir_names = {'test', 'tests', '__tests__', 'spec', 'fixtures'}
            try:
                parts = Path(file_path).parts
                if any(pname in test_dir_names for pname in parts):
                    return True
            except Exception:
                pass

            # filename-based heuristics: ignore files that are test files by naming convention
            try:
                base = os.path.basename(file_path).lower()
                # common test filename patterns: testSomething.js, *.test.js, *.spec.js
                if base.startswith('test') or base.endswith('.test.js') or base.endswith('.spec.js') or base.endswith('_test.js'):
                    return True
            except Exception:
                pass
        except Exception:
            pass
        return False


    def _get_global_excludes(self) -> List[str]:
        """Return the configured global_exclude_paths from config.

        Supports either top-level 'global_exclude_paths' or nested under 'scanner'.
        """
        try:
            # prefer explicit top-level setting
            top = self.config.get('global_exclude_paths')
            excludes = top if top else []

            # also support nested scanner config
            scanner_cfg = self.config.get('scanner', {}) or {}
            if isinstance(scanner_cfg, dict):
                nested = scanner_cfg.get('global_exclude_paths', []) or []
                for p in nested:
                    if p and p not in excludes:
                        excludes.append(p)

            # support a config toggle for internal scanner file filtering
            try:
                cfg = self.config.get('scanner', {}) if self.config.get('scanner') else self.config
                if cfg.get('exclude_internal_scanner_files', False):
                    internal = cfg.get('internal_paths', []) or self.config.get('internal_paths', []) or []
                    for p in internal:
                        if p and p not in excludes:
                            excludes.append(p)
            except Exception:
                # ignore missing nested settings
                pass

            return excludes
        except Exception:
            return []

    def _sanitize_findings(self, findings: List[Dict[str, Any]], target_path: str) -> List[Dict[str, Any]]:
        """Remove malformed findings and those that reference excluded paths.

        Rules:
        - Must be a dict with at least one of: title, description, file_path
        - If file_path exists and matches engine global_exclude_paths, drop it
        - Drop entries that are not dicts or have no meaningful keys
        """
        cleaned = []
        excludes = self._get_global_excludes()

        # load public paths from scanner config (prefix or exact match)
        scanner_cfg = self.config.get('scanner', {}) or {}
        public_paths = scanner_cfg.get('public_paths', []) or []

        for f in findings:
            if not isinstance(f, dict):
                continue

            # basic schema presence
            has_meaning = any(k in f and f.get(k) not in (None, '') for k in ('title', 'description', 'file_path'))
            if not has_meaning:
                continue

            fp = f.get('file_path') or ''
            # normalize file path: if relative, resolve against the scan target
            try:
                if fp and not os.path.isabs(fp):
                    fp_norm = str(Path(target_path, fp).resolve())
                else:
                    fp_norm = str(Path(fp).resolve()) if fp else ''
            except Exception:
                fp_norm = fp

            if fp_norm and self._is_excluded_path(str(fp_norm)):
                continue

            # If finding references an API route path (plugin should put route info in 'route' key),
            # check if it's publicly whitelisted or protected by a global app.use prefix.
            route_path = f.get('route') or ''
            # if plugin didn't set route, try to extract from title like 'Missing JWT Protection: POST /path'
            if not route_path:
                title = f.get('title','') or ''
                # try to find a space + /path pattern
                m = re.search(r"(GET|POST|PUT|DELETE|PATCH)\s+(/[^\s,]*)", title, re.IGNORECASE)
                if m:
                    route_path = m.group(2)
            skip_due_to_route = False
            if route_path:
                # public path exact or prefix match
                for pub in public_paths:
                    if not pub:
                        continue
                    # protect against None
                    rp = route_path or ''
                    if rp == pub or (rp and rp.startswith(pub)):
                        skip_due_to_route = True
                        break

                # check global protected prefixes discovered earlier
                if not skip_due_to_route:
                    prefixes = getattr(self, 'global_protected_prefixes', []) or []
                    for pref in prefixes:
                        if not pref:
                            continue
                        p = pref.rstrip('/')
                        if route_path == p or route_path.startswith(p + '/') or route_path.startswith(pref):
                            skip_due_to_route = True
                            break

            if skip_due_to_route:
                continue

            cleaned.append(f)

        return cleaned
    
    def _should_skip_dir(self, dir_path: str) -> bool:
        """Check if a directory should be skipped"""
        skip_dirs = self.config.get('exclude_directories', [
            'node_modules', '.git', '__pycache__', 'venv', '.venv', 
            'dist', 'build', 'uploads'
        ])
        dir_name = os.path.basename(dir_path)
        return dir_name in skip_dirs
    
    def _is_scannable_file(self, file_path: str) -> bool:
        """Check if a file is scannable"""
        supported_extensions = self.config.get('file_extensions', [
            '.js', '.ts', '.py', '.sql', '.json', '.yaml', '.yml'
        ])
        file_ext = os.path.splitext(file_path)[1].lower()
        return file_ext in supported_extensions
    
    def _generate_summary(self, findings: List[SecurityFinding]) -> Dict[str, Any]:
        """Generate scan summary"""
        summary = {
            'total': len(findings),
            'by_severity': {'CRITICAL': 0, 'HIGH': 0, 'MEDIUM': 0, 'LOW': 0},
            'by_plugin': {}
        }
        
        for finding in findings:
            # Count by severity
            severity = finding.severity.upper()
            if severity in summary['by_severity']:
                summary['by_severity'][severity] += 1

            # Count by plugin
            plugin_name = finding.plugin or 'Unknown'
            if plugin_name not in summary['by_plugin']:
                summary['by_plugin'][plugin_name] = 0
            summary['by_plugin'][plugin_name] += 1
        
        return summary
    
    def _get_timestamp(self) -> str:
        """Get timestamp"""
        from datetime import datetime
        return datetime.now().isoformat()
    
    def get_scan_stats(self) -> Dict[str, Any]:
        """Get scan statistics"""
        return self.stats.copy()

    def _generate_recommendation(self, finding_type: str, file_path: str) -> str:
        """Generate specific recommendations based on finding type."""
        # Return a structured recommendation dict
        if "JWT" in finding_type:
            return {
                'summary': 'Add JWT authentication middleware to the route.',
                'steps': [
                    "Import the middleware if missing: const { authenticateToken } = require('../middleware/authenticateToken');",
                    "Add middleware to the route: e.g. router.post('/', authenticateToken, (req, res) => { ... });",
                    "Consider optional authentication helper if needed: const { optionalAuth } = require('../middleware/authenticateToken');",
                    "Verify token lifetimes and error handling policies."
                ],
                'code': "const { authenticateToken } = require('../middleware/authenticateToken');\nrouter.post('/', authenticateToken, (req, res) => { ... });"
            }
        
        # Add more recommendation types as needed
        return {
            'summary': 'Review this finding and apply best-practice remediation steps.',
            'steps': ["Investigate the issue details.", "Apply an appropriate fix and test."],
            'code': ''
        }


# Backwards compatibility: keep old name as an alias for imports in other modules/tests
SecurityScannerEngine = VulnerabilityScannerEngine